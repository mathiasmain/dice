{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7233668,"sourceType":"datasetVersion","datasetId":4188669}],"dockerImageVersionId":30787,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#! pip install imutils\n#!pip install tqdm\n#! pip install kaggle\n\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.datasets import mnist\nfrom tqdm import tqdm\nfrom skimage.io import imshow\nfrom keras.preprocessing import image\nimport tensorflow.keras.utils as np_utils\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix,f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom tensorflow.keras.utils import img_to_array , to_categorical\nfrom tensorflow.keras import layers, models\n\n# import supervision to visualize our results\n\n# import cv2 to helo load our image\nimport os\nimport random\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Jesus help me","metadata":{}},{"cell_type":"code","source":"\n#os.listdir(\"/kaggle/input/affectnet/AffectNet/train\")\n\n#for dirname, _, filenames in os.walk('/kaggle/input/affectnet/AffectNet/train'):\n#   for filename in filenames:\n#        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"fahdashdah","metadata":{}},{"cell_type":"code","source":"def numtoemotion(a):\n    match a:\n      case 0 | \"0\":\n        return \"Irritação\"\n      case 3 | \"3\":\n        return \"Felicidade\"\n      case 4 | \"4\":\n        return \"Tristeza\"\n      case 5 | \"5\":\n        return \"Surpresa\"\n      case 6 | \"6\":\n        return \"Neutralidade\"\n      case _:\n        return \"Erro\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Substituindo imutils","metadata":{}},{"cell_type":"code","source":"\nimage_types = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n\n\ndef list_images(basePath, contains=None):\n    # return the set of files that are valid\n    return list_files(basePath, validExts=image_types, contains=contains)\n\n\ndef list_files(basePath, validExts=None, contains=None):\n    # loop over the directory structure\n    for (rootDir, dirNames, filenames) in os.walk(basePath):\n        # loop over the filenames in the current directory\n        for filename in filenames:\n            # if the contains string is not none and the filename does not contain\n            # the supplied string, then ignore the file\n            if contains is not None and filename.find(contains) == -1:\n                continue\n\n            # determine the file extension of the current file\n            ext = filename[filename.rfind(\".\"):].lower()\n\n            # check to see if the file is an image and should be processed\n            if validExts is None or ext.endswith(validExts):\n                # construct the path to the image and yield it\n                imagePath = os.path.join(rootDir, filename)\n                yield imagePath","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path_dataset = \"/kaggle/input/AffectNet/train/\"\n\n#Carrega a lista de labels\ndir = os.listdir(path_dataset)\nprint(dir)\nvarname = []\nfor i in dir:\n    if i==\"0\" or i==\"3\" or i==\"4\" or i==\"5\" or i==\"6\":\n        varname.append(i)\n    else:\n        continue\nprint(varname)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nlabel_dict = {}\n\n\n\nfor i, d in enumerate(sorted(varname)):\n    label_dict[d] = i\n    print(d,\" - \",numtoemotion(d))\n\n\nprint(\"\\n\")\nprint(\"label_dict: \",label_dict)\n\n#Calcula a quantidade de classes\nnum_classes = len(label_dict)\n\nprint(\"Número de classes: \", num_classes) # deve dar 5\n\n# neutralidade(6),\n# felicidade(3),\n# irritação(0),\n# surpresa(5)\n# tristeza(4)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Oh God, no","metadata":{}},{"cell_type":"code","source":"# grab the image paths and randomly shuffle them\nunorderedImgPaths = list_images(path_dataset)\n\n# unorderedImgPaths virá como '/kaggle/input/affectnet/AffectNet/train/6/image0017435.jpg'\n# Quem estive na pasta 0,3,4,5 e 6 servirá para criar o modelo\nselectedImgPaths = []\nfor path in unorderedImgPaths:\n    match path.split(os.path.sep)[-2]:\n        case 0 | \"0\" | 3 | \"3\" | 4 | \"4\" | 5 | \"5\" | 6 | \"6\":\n            selectedImgPaths.append(path)\n        case _: continue\n\nassert len(selectedImgPaths) != 0\n    \n    \n\nimagePaths = sorted(list(selectedImgPaths))\nprint(\"Verifique os seguintes caminhos: \", imagePaths[-5:])\nrandom.seed(42)\nrandom.shuffle(imagePaths)\n#print(imagePaths)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"anything but this","metadata":{}},{"cell_type":"code","source":"labels = []\ndata = []\nnone_image = 0\n\nprint(\"[INFO] loading images...\")\n# loop over the input images\n\nfor imagePath in tqdm(imagePaths):\n    # load the image, pre-process it, and store it in the data list\n    # print(f\"image_path=\\n{imagePath}\")\n    image = cv2.imread(imagePath)\n    if image is not None:\n        # print(f\"image=\\n{image}\")\n        image = cv2.resize(image, (80, 80))\n        \n        #Converts Image instance to a Numpy array\n        image = img_to_array(image)\n        data.append(image)\n\n        # extract the class label from the image path and update the\n        # labels list\n\n\n        label = label_dict[imagePath.split(os.path.sep)[-2]]\n        # print(label)\n        labels.append(label)\n    else:\n        none_image += 1\n       \n\nprint(none_image)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"ugh","metadata":{}},{"cell_type":"code","source":"# scale the raw pixel intensities to the range [0, 1]\ndata = np.array(data, dtype=\"float\") / 255.0\nlabels = np.array(labels)\n\n# partition the data into training and testing splits using 50% of\n# the data for training and the remaining 50% for testing\n(train_images, test_images, train_l, test_l) = train_test_split( data, labels, test_size=0.25, random_state=42)\n#print(train_l)\n#print(test_l)\n#print(num_classes)\n# convert the labels from integers to vectors\ntrain_labels = np_utils.to_categorical(train_l, num_classes=num_classes)\ntest_labels = np_utils.to_categorical(test_l, num_classes=num_classes)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**\"l-l\"**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    img_float32 = np.float32(train_images[i])\n    plt.imshow(img_float32)\n    # labels\n    plt.xlabel( [k for k, v in label_dict.items() if v == train_l[i]][0] )\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Data shape","metadata":{}},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"someone, please, just save me","metadata":{}},{"cell_type":"code","source":"\n#exemplo1\n#face_classifier = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n#classifier = load_model(\"./Emotion_Detection.h5\")\n#class_labels = ['Angry', 'Happy', 'Neutral', 'Sad', 'Surprise']\n\n\n#exemplo 2\n\n\n\n# load a pre-trained yolov8n model\nmodel = load_model(model_id=\"yolov10n-640\")\n\n# run inference on our chosen image, image can be a url, a numpy array, a PIL image, etc.\n\n\n# ---------------------------------------\n\n#model = models.Sequential()\n#model.add(layers.Conv2D(80, kernel_size=(3, 3), activation='relu', input_shape=(80, 80, 3))) # 3 é sobre RGB\n#model.add(layers.MaxPooling2D((2, 2)))\n#model.add(layers.Conv2D(160, kernel_size=(3, 3), activation='relu'))\n#model.add(layers.MaxPooling2D((2, 2)))\n#model.add(layers.Flatten())\n#model.add(layers.Dropout(0.5))\n#model.add(layers.Dense(160, activation='relu')) # Dense: Núm. neurônios 1a cam\n#model.add(layers.Dense(40, activation='relu')) # Dense: Núm. neurônios 1a cam\n#model.add(layers.Dense(num_classes, activation=\"softmax\"))\n# Conv2D( 80 ) -> Conv2D( 160 ) -> Dense( 160 ) -> Dense( 40 ) -> Dense( 40 ) -> Dense( 5 )\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"wait what","metadata":{}},{"cell_type":"code","source":"#model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nhistory = model.fit(train_images, train_l, epochs=100, batch_size=20,\n                    validation_data=(test_images, test_l))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"i am breathing","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(loc='best')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"I AM BREATHING","metadata":{}},{"cell_type":"code","source":"print(\"Generating test predictions...\")\npredict_x=model.predict(test_images)\nprint(np.around(predict_x, 2))\n\n# make class predictions\npredictions = (predict_x > 0.5).astype(int)\n\ny_pred_class = np.argmax(predictions, axis=1)\ny_test_class = np.argmax(test_labels, axis=1)\n\nfor i in range(len(test_labels)):\n\tif y_pred_class[i] == y_test_class[i]:\n\t\tprint(f'\\033[92m {y_pred_class[i]} (expected {y_test_class[i]})')\n\telse:\n\t\tprint(f'\\033[91m {y_pred_class[i]} (expected {y_test_class[i]})')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"oH NO hE CAMEBACK AGAIN","metadata":{}},{"cell_type":"code","source":"# Avaliando a acurácia com as imagens de Teste\nl = len(y_test_class)\ny_test2 = y_test_class\ny_pred2 = y_pred_class\nacc = sum([y_pred_class[i]==y_test_class[i] for i in range(l)])/l\nprint('Accuracy: %.2f %%' % (acc*100))\n\nf1score = 0\nf1score += f1_score(y_test2,y_pred2,average=\"weighted\")\nprint(\"F_measure: \",round(100*f1score, 2),\"%\")\n# Calcular com F_meansure\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#nOOOOOO MORE TYPELESS STUFF, PLEASE","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# voltando pro formato de classes\ny_pred = np.argmax(predictions, axis=1)\ny_test_c = np.argmax(test_labels, axis=1)\n\n\n#Confusion Matrix\ncm = confusion_matrix(y_test_c, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=numtoemotion(label_dict))\ndisp.plot(cmap=plt.cm.Blues)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"ok, just one more fucking sip into python","metadata":{}},{"cell_type":"code","source":"model.save(r'./kaggle/working/dice.hdf5')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}